{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moviefy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideEva/Moviefy/blob/main/Moviefy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cIJV64OLD8N"
      },
      "source": [
        "# Problem analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9K_1ajnk6i"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO4pM6X-woCT"
      },
      "source": [
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XCqb1vMvbSF"
      },
      "source": [
        "films_data = {\n",
        "    \"Ghibli\": \"1RR18MAxLoZQWsxrmfb1hYif2MhOcsgO2\"\n",
        "}\n",
        "keys = list(films_data.keys())\n",
        "ghibli_index = 0\n",
        "films_data[keys[ghibli_index]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFFC2I7nmIK"
      },
      "source": [
        "def load_data(name, id_txt):\n",
        "\n",
        "  file_name = f'list-{name}.txt'\n",
        "\n",
        "  ! gdown --id \"$id_txt\" -O \"$file_name\"\n",
        "\n",
        "  lines = []\n",
        "  with open(file_name, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  ! mkdir \"$name\"\n",
        "\n",
        "  for line in lines:\n",
        "    id = line.strip()\n",
        "    ! cd \"$name\" && gdown --id \"$id\"\n",
        "\n",
        "  zip_files = glob(f'{name}/*.zip')\n",
        "  for zip_file in zip_files:\n",
        "    ! unzip -qo \"$zip_file\" -d \"$name\"\n",
        "    ! rm \"$zip_file\"\n",
        "  \n",
        "  return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA9UnZ6nqhwK"
      },
      "source": [
        "folders = [load_data(studio_name, id_list_id) for studio_name, id_list_id in films_data.items()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtTLjUKToxO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYnk7xOGrwh"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, InputSpec, LeakyReLU, Input, Conv2D, Activation, Concatenate, Conv2DTranspose, BatchNormalization, AveragePooling2D, Add\n",
        "from tensorflow import pad\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDgBWEGvLwk0"
      },
      "source": [
        "# Plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dgW_xG1LxOB"
      },
      "source": [
        "def plot_grid(images, columns, show_axis=False, labels=None):\n",
        "  if len(images) == 0 or columns <= 0:\n",
        "    return\n",
        "  height = 1 + math.ceil(len(images) / columns) * 2\n",
        "  width = columns * 4\n",
        "  dpi = max(images[0].shape[0], images[0].shape[1]) // 2\n",
        "  fig = plt.figure(figsize=(width, height), dpi=dpi)\n",
        "  fig.subplots_adjust(hspace=0.4)\n",
        "  for index, img in enumerate(images, start=1):\n",
        "    if 'float' in img.dtype.str:\n",
        "      img = (img * 255).astype('uint8')\n",
        "    sp = fig.add_subplot(math.ceil(len(images) / columns), columns, index)\n",
        "    if not show_axis:\n",
        "      plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    if labels is not None:\n",
        "      l = len(labels)\n",
        "      sp.set_title(labels[(index-1) % l], fontsize=10)\n",
        "    else:\n",
        "      sp.set_title(index, fontsize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4OJRPRrvTD"
      },
      "source": [
        "# Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ort4c0Hvkv"
      },
      "source": [
        "raw_size = (1080, 1920, 3)\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 32\n",
        "validation_split = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4x-hbYuR4l"
      },
      "source": [
        "# Dataset loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9p_GeCJWICD"
      },
      "source": [
        "def smooth_edges(img):\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCRHDcmuWxJ"
      },
      "source": [
        "data_generator_settings = {\n",
        "    'data_format' : 'channels_last',\n",
        "    'validation_split' : validation_split,\n",
        "    'rescale' : 1.0 / 255\n",
        "}\n",
        "\n",
        "data_flow_settings = {\n",
        "    'target_size' : target_size,\n",
        "    'color_mode' : 'rgb',\n",
        "    'class_mode' : None,\n",
        "    'batch_size' : batch_size,\n",
        "    'shuffle' : True,\n",
        "    'interpolation' : 'bilinear'\n",
        "}\n",
        "\n",
        "cartoon_real_generator = ImageDataGenerator(\n",
        "    **data_generator_settings\n",
        ")\n",
        "\n",
        "cartoon_edge_fake_generator = ImageDataGenerator(\n",
        "    **data_generator_settings,\n",
        "    preprocessing_function = smooth_edges\n",
        ")\n",
        "\n",
        "# Same proportions as raw, same height as desired input\n",
        "target_size = (input_shape[0], raw_size[1] * input_shape[0] // raw_size[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fa7QGBqV97F"
      },
      "source": [
        "def random_cropper_generator(batches, size):\n",
        "  def random_crop(img):\n",
        "    left = bool(random.getrandbits(1))\n",
        "    if left:\n",
        "      return img[:, 0:size[1], :]\n",
        "    return img[:, -size[1]:, :]\n",
        "  for batch in batches:\n",
        "    yield [random_crop(i) for i in batch]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqumAei81Roa"
      },
      "source": [
        "test_cartoon_real_flow = random_cropper_generator(\n",
        "  cartoon_real_generator.flow_from_directory(\n",
        "    **data_flow_settings,\n",
        "    directory = folders[ghibli_index],\n",
        "    subset = 'training',\n",
        "  ),\n",
        "  input_shape\n",
        ")\n",
        "plot_grid(next(test_cartoon_real_flow), 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQrSxTqRX2oM"
      },
      "source": [
        "test_cartoon_edge_fake_flow = random_cropper_generator(\n",
        "  cartoon_edge_fake_generator.flow_from_directory(\n",
        "    **data_flow_settings,\n",
        "    directory = folders[ghibli_index],\n",
        "    subset = 'training',\n",
        "  ),\n",
        "  input_shape\n",
        ")\n",
        "plot_grid(next(test_cartoon_edge_fake_flow), 4)\n",
        "del test_cartoon_edge_fake_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZfIsl-rzgH"
      },
      "source": [
        "# Cartoon-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdnnqJrr49p"
      },
      "source": [
        "## Utility Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZVztXmxfqh"
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "  def __init__(self, padding=(1, 1), **kwargs):\n",
        "    self.padding = tuple(padding)\n",
        "    # self.input_spec = [InputSpec(ndim=4)]\n",
        "    super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "  def compute_output_shape(self, s):\n",
        "    if s[1] == None:\n",
        "      return (None, None, None, s[3])\n",
        "    return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    w_pad, h_pad = self.padding\n",
        "    return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(ReflectionPadding2D, self).get_config()\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_eKtrzX8eS"
      },
      "source": [
        "class Conv2DReflection3x3(Layer):\n",
        "  def __init__(self, features, stride=1):\n",
        "    super().__init__()\n",
        "    self.reflectionPadding2D = ReflectionPadding2D()\n",
        "    self.conv2d = Conv2D(features, (3,3), strides=(stride, stride), padding='valid', use_bias=False)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.reflectionPadding2D(inputs, training=training)\n",
        "    return self.conv2d(x, training=training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QosKh8nXwVDy"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWKAZhc0TtT8"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # k3n32s1\n",
        "  d = Conv2DReflection3x3(32, stride=1)(in_image)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n64s2\n",
        "  d = Conv2DReflection3x3(64, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n128s1\n",
        "  d = Conv2DReflection3x3(128, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n128s2\n",
        "  d = Conv2DReflection3x3(128, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # feature construction block\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # patch output\n",
        "  patch_out = Conv2DReflection3x3(1, stride=1)(d)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, patch_out)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTqNuZ0TuIb"
      },
      "source": [
        "D = define_discriminator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aL1dg_7WxKG"
      },
      "source": [
        "plot_model(D, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmXCQikgsCVj"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQsEIexgEot"
      },
      "source": [
        "# define the generator model\n",
        "def define_generator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # flat block\n",
        "  # k7n64s1\n",
        "  g = Conv2D(64, (7,7), strides=1, padding='same', use_bias=False)(in_image)\n",
        "  g = BatchNormalization(epsilon=epsilon, momentum=momentum)(g)\n",
        "  g = LeakyReLU(alpha=alpha)(g)\n",
        "\n",
        "  def down_block(x, n_features):\n",
        "    # k3n?s2\n",
        "    x = Conv2DReflection3x3(n_features, stride=2)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st down block\n",
        "  g = down_block(g, 128)\n",
        "\n",
        "  # 2nd down block\n",
        "  g = down_block(g, 256)\n",
        "\n",
        "  def resiual_block(x):\n",
        "    skip = x\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = Add()([x, skip])\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  for _ in range(8):\n",
        "    g = resiual_block(g)\n",
        "\n",
        "  def up_block(x, n_features):\n",
        "    # k3n?s1/2\n",
        "    x = Conv2DTranspose(n_features, (3,3), strides=2)(x)\n",
        "    x = AveragePooling2D(pool_size=(2,2), strides=1)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st up block\n",
        "  g = up_block(g, 128)\n",
        "\n",
        "  # 2nd up-block\n",
        "  g = up_block(g, 64)\n",
        "\n",
        "  # k7n3s1\n",
        "  output = Conv2D(3, (7,7), strides=1, padding='same')(g)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbrwJll72Jc"
      },
      "source": [
        "G = define_generator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJA_a7l72Jc"
      },
      "source": [
        "plot_model(G, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKihPPW_WkZ"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1I8Kc6wYRka"
      },
      "source": [
        "def BCEWithLogitsLoss():\n",
        "  return tf.keras.losses.BinaryCrossEntropy(\n",
        "    from_logits=True,\n",
        "    reduction=tf.keras.losses.Reduction.NONE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2v-V58ORS95"
      },
      "source": [
        "class AdversarialLoss:\n",
        "  def __init__(self, cartoon_labels, fake_cartoon_labels):\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "    self.cartoon_labels = cartoon_labels\n",
        "    self.fake_cartoon_labels = fake_cartoon_labels\n",
        "\n",
        "  def __call__(self, cartoon, generated_fake, cartoon_edge_fake):\n",
        "    D_cartoon_loss = self.base_loss(cartoon, self.cartoon_labels)\n",
        "    D_generated_fake_loss = self.base_loss(generated_fake, self.fake_cartoon_labels)\n",
        "    D_edge_fake_loss = self.base_loss(cartoon_edge_fake, self.fake_cartoon_labels)\n",
        "\n",
        "    return D_cartoon_loss + D_generated_fake_loss + D_edge_fake_loss\n",
        "\n",
        "# alias for clarity\n",
        "DiscriminatorLoss = AdversarialLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPZxQNSVtr6"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "class ContentLoss:\n",
        "  def __init__(self):\n",
        "    self.perception = vgg19.predict\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    diff = self.perception(outputs) - self.perception(inputs)\n",
        "    k = tf.norm(diff, ord=1)\n",
        "    return k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGF728qWboj"
      },
      "source": [
        "class GeneratorLoss:\n",
        "  def __init__(self, omega=10):\n",
        "    self.omega = omega\n",
        "    self.content_loss = ContentLoss()\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    return self.base_loss(outputs, inputs) + self.omega * self.content_loss(outputs, inputs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}