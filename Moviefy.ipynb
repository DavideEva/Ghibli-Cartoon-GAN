{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moviefy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideEva/Moviefy/blob/main/Moviefy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cIJV64OLD8N"
      },
      "source": [
        "# Problem analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9K_1ajnk6i"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XCqb1vMvbSF"
      },
      "source": [
        "films_data = {\n",
        "    \"Ghibli\": \"1RR18MAxLoZQWsxrmfb1hYif2MhOcsgO2\"\n",
        "}\n",
        "keys = list(films_data.keys())\n",
        "ghibli_index = 0\n",
        "films_data[keys[ghibli_index]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFFC2I7nmIK"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "def load_data(name, id_txt):\n",
        "\n",
        "  file_name = f'list-{name}.txt'\n",
        "\n",
        "  ! gdown --id \"$id_txt\" -O \"$file_name\"\n",
        "\n",
        "  lines = []\n",
        "  with open(file_name, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  ! mkdir \"$name\"\n",
        "\n",
        "  for line in lines:\n",
        "    id = line.strip()\n",
        "    ! cd \"$name\" && gdown --id \"$id\"\n",
        "\n",
        "  zip_files = glob(f'{name}/*.zip')\n",
        "  for zip_file in zip_files:\n",
        "    ! unzip -qo \"$zip_file\" -d \"$name\"\n",
        "    ! rm \"$zip_file\"\n",
        "  \n",
        "  return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA9UnZ6nqhwK"
      },
      "source": [
        "folders = [load_data(studio_name, id_list_id) for studio_name, id_list_id in films_data.items()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtTLjUKToxO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYnk7xOGrwh"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, InputSpec, LeakyReLU, Input, Conv2D, Activation, Concatenate, Conv2DTranspose, BatchNormalization, AveragePooling2D, Add\n",
        "from tensorflow import pad\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDgBWEGvLwk0"
      },
      "source": [
        "# Plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dgW_xG1LxOB"
      },
      "source": [
        "def plot_grid(images, columns, show_axis=False, labels=None):\n",
        "  if len(images) == 0 or columns <= 0:\n",
        "    return\n",
        "  height = 1 + math.ceil(len(images) / columns) * 2\n",
        "  width = columns * 4\n",
        "  dpi = max(images[0].shape[0], images[0].shape[1]) // 2\n",
        "  fig = plt.figure(figsize=(width, height), dpi=dpi)\n",
        "  fig.subplots_adjust(hspace=0.4)\n",
        "  for index, img in enumerate(images, start=1):\n",
        "    if 'float' in img.dtype.str:\n",
        "      img = (img * 255).astype('uint8')\n",
        "    sp = fig.add_subplot(math.ceil(len(images) / columns), columns, index)\n",
        "    if not show_axis:\n",
        "      plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    if labels is not None:\n",
        "      l = len(labels)\n",
        "      sp.set_title(labels[(index-1) % l], fontsize=10)\n",
        "    else:\n",
        "      sp.set_title(index, fontsize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4OJRPRrvTD"
      },
      "source": [
        "# Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ort4c0Hvkv"
      },
      "source": [
        "# The raw image as found in dataset files. The important part is the width/height proportion. In this case, 16:9.\n",
        "raw_shape = (1080, 1920, 3)\n",
        "\n",
        "# The same as https://github.com/FilipAndersson245/cartoon-gan/blob/5a09f4e2cfad42accfc1792dedfba95f9ab6fb83/utils/datasets.py#L32\n",
        "# Should be less than input shape\n",
        "preprocess_shape = (384, 384, 3)\n",
        "\n",
        "# Dimension after the preprocess stage\n",
        "# Should be the dimension expected by the network and the loss functions\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Batch size used for training and fetching images\n",
        "batch_size = 32\n",
        "\n",
        "# Images are split between train+validation and test set at this proportion\n",
        "validation_split = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4x-hbYuR4l"
      },
      "source": [
        "# Dataset loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9p_GeCJWICD"
      },
      "source": [
        "def smooth_edges(img):\n",
        "  # Parameters taken from https://github.com/FilipAndersson245/cartoon-gan/blob/master/utils/datasets.py\n",
        "  kernel_size = 5\n",
        "  pad_size = kernel_size // 2 + 1\n",
        "  gray_img = cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n",
        "  pad_img = np.pad(img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='reflect')\n",
        "  edges = cv2.Canny(gray_img, 150, 500)\n",
        "  dilation = cv2.dilate(edges, np.ones((kernel_size, kernel_size), np.uint8))\n",
        "  gauss = cv2.getGaussianKernel(kernel_size, 0)\n",
        "  gauss = gauss * gauss.transpose(1, 0)\n",
        "  idx = np.where(dilation != 0)\n",
        "  loops = len(idx[0])\n",
        "  gauss_img = np.copy(img)\n",
        "  for i in range(loops):\n",
        "    #debug edges detection: \n",
        "    #gauss_img[idx[0][i], idx[1][i], 0] = 1.0\n",
        "    #gauss_img[idx[0][i], idx[1][i], 1] = 1.0\n",
        "    #gauss_img[idx[0][i], idx[1][i], 2] = 0.0\n",
        "    gauss_img[idx[0][i], idx[1][i], 0] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 0], gauss))\n",
        "    gauss_img[idx[0][i], idx[1][i], 1] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 1], gauss))\n",
        "    gauss_img[idx[0][i], idx[1][i], 2] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 2], gauss))\n",
        "  return gauss_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fa7QGBqV97F"
      },
      "source": [
        "def left_cropper(pre = lambda x: x):\n",
        "  def left_crop(img):\n",
        "      img = pre(img)\n",
        "      return img[:, 0:img.shape[0], :]\n",
        "  return left_crop \n",
        "def right_cropper(pre = lambda x: x):\n",
        "  def right_crop(img):\n",
        "    img = pre(img)\n",
        "    return img[:, -img.shape[0]:, :]\n",
        "  return right_crop\n",
        "def smoother(pre = lambda x: x):\n",
        "  return lambda img: smooth_edges(pre(img))\n",
        "def resizer(size, pre = lambda x: x):\n",
        "  return lambda img: cv2.resize(pre(img), (size[1], size[0]), interpolation=cv2.INTER_AREA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeiQb3KOQd3V"
      },
      "source": [
        "def lambda_generator(batches, λ = lambda x: x):\n",
        "  for batch in batches:\n",
        "    yield [λ(i) for i in batch]\n",
        "\n",
        "def random_merge_generator(it_1, it_2, p = 0.5):\n",
        "  while True:\n",
        "    rand = np.random.random()\n",
        "    it, other = (it_1, it_2) if rand < p else (it_2, it_1)\n",
        "    try:\n",
        "      yield next(it)\n",
        "    except StopIteration:\n",
        "      while True:\n",
        "        yield next(other)\n",
        "\n",
        "def cartoon_generator(pre = lambda x: x, preprocess_shape = preprocess_shape, raw_shape = raw_shape):\n",
        "  return lambda_generator(\n",
        "      cartoon_real_generator.flow_from_directory(\n",
        "        **data_flow_settings,\n",
        "        directory = folders[ghibli_index],\n",
        "        subset = 'training',\n",
        "        # Same proportions as raw, same height as desired input\n",
        "        target_size = (preprocess_shape[0], raw_shape[1] * preprocess_shape[0] // raw_shape[0])\n",
        "      ),\n",
        "      pre\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCRHDcmuWxJ"
      },
      "source": [
        "data_generator_settings = {\n",
        "    'data_format' : 'channels_last',\n",
        "    'validation_split' : validation_split,\n",
        "    'rescale' : 1.0 / 255\n",
        "}\n",
        "\n",
        "data_flow_settings = {\n",
        "    'color_mode' : 'rgb',\n",
        "    'class_mode' : None,\n",
        "    'batch_size' : batch_size,\n",
        "    'shuffle' : True,\n",
        "    'interpolation' : 'bilinear'\n",
        "}\n",
        "\n",
        "cartoon_real_generator = ImageDataGenerator(\n",
        "    **data_generator_settings\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqumAei81Roa"
      },
      "source": [
        "test_cartoon_real_flow = random_merge_generator(\n",
        "  cartoon_generator(left_cropper(), input_shape),\n",
        "  cartoon_generator(right_cropper(), input_shape)\n",
        ")\n",
        "plot_grid(next(test_cartoon_real_flow), 4)\n",
        "del test_cartoon_real_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQrSxTqRX2oM"
      },
      "source": [
        "test_cartoon_edge_fake_flow = random_merge_generator(\n",
        "  cartoon_generator(resizer(input_shape, smoother(left_cropper())), preprocess_shape),\n",
        "  cartoon_generator(resizer(input_shape, smoother(right_cropper())), preprocess_shape)\n",
        ")\n",
        "plot_grid(next(test_cartoon_edge_fake_flow), 4)\n",
        "del test_cartoon_edge_fake_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZfIsl-rzgH"
      },
      "source": [
        "# Cartoon-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdnnqJrr49p"
      },
      "source": [
        "## Utility Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZVztXmxfqh"
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "  def __init__(self, padding=(1, 1), **kwargs):\n",
        "    self.padding = tuple(padding)\n",
        "    # self.input_spec = [InputSpec(ndim=4)]\n",
        "    super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "  def compute_output_shape(self, s):\n",
        "    if s[1] == None:\n",
        "      return (None, None, None, s[3])\n",
        "    return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    w_pad, h_pad = self.padding\n",
        "    return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(ReflectionPadding2D, self).get_config()\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_eKtrzX8eS"
      },
      "source": [
        "class Conv2DReflection3x3(Layer):\n",
        "  def __init__(self, features, stride=1):\n",
        "    super().__init__()\n",
        "    self.reflectionPadding2D = ReflectionPadding2D()\n",
        "    self.conv2d = Conv2D(features, (3,3), strides=(stride, stride), padding='valid', use_bias=False)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.reflectionPadding2D(inputs, training=training)\n",
        "    return self.conv2d(x, training=training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QosKh8nXwVDy"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWKAZhc0TtT8"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # k3n32s1\n",
        "  d = Conv2DReflection3x3(32, stride=1)(in_image)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n64s2\n",
        "  d = Conv2DReflection3x3(64, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n128s1\n",
        "  d = Conv2DReflection3x3(128, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n128s2\n",
        "  d = Conv2DReflection3x3(128, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # feature construction block\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # patch output\n",
        "  patch_out = Conv2DReflection3x3(1, stride=1)(d)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, patch_out)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTqNuZ0TuIb"
      },
      "source": [
        "D = define_discriminator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aL1dg_7WxKG"
      },
      "source": [
        "plot_model(D, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmXCQikgsCVj"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQsEIexgEot"
      },
      "source": [
        "# define the generator model\n",
        "def define_generator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # flat block\n",
        "  # k7n64s1\n",
        "  g = Conv2D(64, (7,7), strides=1, padding='same', use_bias=False)(in_image)\n",
        "  g = BatchNormalization(epsilon=epsilon, momentum=momentum)(g)\n",
        "  g = LeakyReLU(alpha=alpha)(g)\n",
        "\n",
        "  def down_block(x, n_features):\n",
        "    # k3n?s2\n",
        "    x = Conv2DReflection3x3(n_features, stride=2)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st down block\n",
        "  g = down_block(g, 128)\n",
        "\n",
        "  # 2nd down block\n",
        "  g = down_block(g, 256)\n",
        "\n",
        "  def resiual_block(x):\n",
        "    skip = x\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = Add()([x, skip])\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  for _ in range(8):\n",
        "    g = resiual_block(g)\n",
        "\n",
        "  def up_block(x, n_features):\n",
        "    # k3n?s1/2\n",
        "    x = Conv2DTranspose(n_features, (3,3), strides=2)(x)\n",
        "    x = AveragePooling2D(pool_size=(2,2), strides=1)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st up block\n",
        "  g = up_block(g, 128)\n",
        "\n",
        "  # 2nd up-block\n",
        "  g = up_block(g, 64)\n",
        "\n",
        "  # k7n3s1\n",
        "  output = Conv2D(3, (7,7), strides=1, padding='same')(g)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbrwJll72Jc"
      },
      "source": [
        "G = define_generator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJA_a7l72Jc"
      },
      "source": [
        "plot_model(G, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKihPPW_WkZ"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1I8Kc6wYRka"
      },
      "source": [
        "def BCEWithLogitsLoss():\n",
        "  return tf.keras.losses.BinaryCrossEntropy(\n",
        "    from_logits=True,\n",
        "    reduction=tf.keras.losses.Reduction.NONE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2v-V58ORS95"
      },
      "source": [
        "class AdversarialLoss:\n",
        "  def __init__(self, cartoon_labels, fake_cartoon_labels):\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "    self.cartoon_labels = cartoon_labels\n",
        "    self.fake_cartoon_labels = fake_cartoon_labels\n",
        "\n",
        "  def __call__(self, cartoon, generated_fake, cartoon_edge_fake):\n",
        "    D_cartoon_loss = self.base_loss(cartoon, self.cartoon_labels)\n",
        "    D_generated_fake_loss = self.base_loss(generated_fake, self.fake_cartoon_labels)\n",
        "    D_edge_fake_loss = self.base_loss(cartoon_edge_fake, self.fake_cartoon_labels)\n",
        "\n",
        "    return D_cartoon_loss + D_generated_fake_loss + D_edge_fake_loss\n",
        "\n",
        "# alias for clarity\n",
        "DiscriminatorLoss = AdversarialLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPZxQNSVtr6"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "class ContentLoss:\n",
        "  def __init__(self):\n",
        "    self.perception = vgg19.predict\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    diff = self.perception(outputs) - self.perception(inputs)\n",
        "    k = tf.norm(diff, ord=1)\n",
        "    return k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGF728qWboj"
      },
      "source": [
        "class GeneratorLoss:\n",
        "  def __init__(self, omega=10):\n",
        "    self.omega = omega\n",
        "    self.content_loss = ContentLoss()\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    return self.base_loss(outputs, inputs) + self.omega * self.content_loss(outputs, inputs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}