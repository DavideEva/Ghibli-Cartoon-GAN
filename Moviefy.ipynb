{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Moviefy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideEva/Moviefy/blob/main/Moviefy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cIJV64OLD8N"
      },
      "source": [
        "# Problem analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9K_1ajnk6i"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WdF4y4poYid"
      },
      "source": [
        "from glob import glob\n",
        "flickr30k_folder = 'Flickr30k-images-preprocessed'\n",
        "! rm -rf sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUU6tAJDObT"
      },
      "source": [
        "! mkdir \"$flickr30k_folder\" && \\\n",
        "gdown --id \"10c0Xruu2wAE-FpQEIlXm17HlwQAJKKVM\" && \\\n",
        "unzip -qo flickr30k-images-preprocessed.zip -d \"$flickr30k_folder\" && \\\n",
        "rm flickr30k-images-preprocessed.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFFC2I7nmIK"
      },
      "source": [
        "films_data = {\n",
        "    \"Ghibli\": \"1bR_BE-ZZSXW1URBJqPIMFo9VLODYb4_k\"\n",
        "}\n",
        "ghibli_index = 0\n",
        "real_folder = 'real'\n",
        "smooth_folder = 'smooth'\n",
        "\n",
        "def load_data(id, name):\n",
        "  ! [ ! -d \"$name\" ] && mkdir -p \"$name\" && cd \"$name\" && gdown --id \"$id\"\n",
        "  zip_files = glob(f'{name}/*.zip')\n",
        "  for zip_file in zip_files:\n",
        "    ! unzip -qo \"$zip_file\" -d \"$name\"\n",
        "    ! rm \"$zip_file\"\n",
        "  return name\n",
        "\n",
        "folders = [load_data(id_drive, studio_name) for studio_name, id_drive in films_data.items()]\n",
        "print(folders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5tDATAlpXuL"
      },
      "source": [
        "Folder structure:\n",
        "```bash\n",
        ".\n",
        "├── Studio_Name\n",
        "|   ├── real\n",
        "|   |   └── Movie_Name_1\n",
        "|   |       ├── Scene-1\n",
        "|   |       |   ├── left\n",
        "|   |       |   |   ├── 0.jpg\n",
        "|   |       |   |   ...\n",
        "|   |       |   |   └──\n",
        "|   |       |   └── right\n",
        "|   |       |       ├── 0.jpg\n",
        "|   |       |       ...\n",
        "|   |       |       └──\n",
        "|   |       ├── Scene-2\n",
        "|   |       ...\n",
        "|   |       └──\n",
        "|   |   \n",
        "|   └── smooth\n",
        "|       └── Movie_Name_2\n",
        "|           ├── Scene-1\n",
        "|           |   ├── left\n",
        "|           |   └── right\n",
        "|           ├── Scene-2\n",
        "|           ...\n",
        "|           └──\n",
        "├── Studio_Name_2\n",
        "...\n",
        "└──\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtTLjUKToxO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYnk7xOGrwh"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import psutil\n",
        "import pickle\n",
        "import shutil\n",
        "import os\n",
        "import csv\n",
        "from os import path\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, InputSpec, LeakyReLU, Input, Conv2D, Activation, Concatenate, Conv2DTranspose, BatchNormalization, AveragePooling2D, Add\n",
        "from tensorflow import pad\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "! pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRt3ofKXrb0I"
      },
      "source": [
        "tf.config.list_physical_devices(\"GPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDgBWEGvLwk0"
      },
      "source": [
        "# Plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dgW_xG1LxOB"
      },
      "source": [
        "def plot_grid(images, columns, show_axis=False, labels=None):\n",
        "  if len(images) == 0 or columns <= 0:\n",
        "    return\n",
        "  scale = 2\n",
        "  height = (1 + math.ceil(len(images) / columns) * 2) * scale\n",
        "  width = (columns * 4) * scale\n",
        "  dpi = max(images[0].shape[0], images[0].shape[1]) // 2\n",
        "  fig = plt.figure(figsize=(width, height), dpi=dpi)\n",
        "  fig.subplots_adjust(hspace=0.4)\n",
        "  for index, img in enumerate(images, start=1):\n",
        "    if 'float' in img.dtype.str:\n",
        "      img = (img * 255).astype('uint8')\n",
        "    sp = fig.add_subplot(math.ceil(len(images) / columns), columns, index)\n",
        "    if not show_axis:\n",
        "      plt.axis('off')\n",
        "    if len(np.shape(img)) == 2 or (len(np.shape(img)) > 2 and np.shape(img)[2] == 1):\n",
        "      plt.imshow(img, cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(img)\n",
        "    if labels is not None:\n",
        "      l = len(labels)\n",
        "      sp.set_title(labels[(index-1) % l], fontsize=10)\n",
        "    else:\n",
        "      sp.set_title(index, fontsize=10)\n",
        "  plt.show()\n",
        "\n",
        "def float_to_int_images(outputs):\n",
        "  return [np.clip(output * 255 + 0.5, 0, 255).astype(np.uint8) for output in outputs] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4OJRPRrvTD"
      },
      "source": [
        "# Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ort4c0Hvkv"
      },
      "source": [
        "# Dimension after the preprocess stage\n",
        "# Should be the dimension expected by the network and the loss functions\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Batch size used for training and fetching images\n",
        "batch_size = 12\n",
        "\n",
        "# Images are split between train+validation and test set at this proportion\n",
        "validation_split = 0.2\n",
        "\n",
        "epochs_count = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4x-hbYuR4l"
      },
      "source": [
        "# Dataset loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeiQb3KOQd3V"
      },
      "source": [
        "def lambda_generator(batches, λ=lambda x: x):\n",
        "  for batch in batches:\n",
        "    if type(batch) is tuple:\n",
        "      batch, labels = batch\n",
        "      yield [λ(i) for i in batch], labels\n",
        "    else:\n",
        "      yield [λ(i) for i in batch]\n",
        "\n",
        "def random_merge_generator(it_1, it_2, p=0.5):\n",
        "  while True:\n",
        "    rand = np.random.random()\n",
        "    it, other = (it_1, it_2) if rand < p else (it_2, it_1)\n",
        "    try:\n",
        "      yield next(it)\n",
        "    except StopIteration:\n",
        "      while True:\n",
        "        yield next(other)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkr9-p-h9bfm"
      },
      "source": [
        "norm_mean = np.asfarray([0.485, 0.456, 0.406])\n",
        "norm_std = np.asfarray([0.229, 0.224, 0.225])\n",
        "\n",
        "def normalize(img):\n",
        "  return (img - norm_mean) / norm_std\n",
        "def unnormalize(img):\n",
        "  return tf.clip_by_value(img * norm_std + norm_mean, 0.0, 1.0)\n",
        "def rescale_and_normalize(img):\n",
        "  return normalize(img / 255.0)\n",
        "\n",
        "def generated_to_images(outputs):\n",
        "  return [unnormalize(output).numpy() for output in outputs]\n",
        "\n",
        "def test():\n",
        "  a = np.asfarray([[[1.0, 0.5, 0.5], [0.0, 0.1, 0.9]], [[0.5, 0.6, 0.7], [1.0, 0.1, 0.2]]])\n",
        "  b = normalize(a)\n",
        "  c = unnormalize(b)\n",
        "  assert np.linalg.norm(c - a) < 0.00001\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCRHDcmuWxJ"
      },
      "source": [
        "data_generator_settings = {\n",
        "    'data_format' : 'channels_last',\n",
        "    'validation_split' : validation_split,\n",
        "    'preprocessing_function' : rescale_and_normalize,\n",
        "    #'rescale' : 1.0 / 255,\n",
        "    'horizontal_flip' : True\n",
        "}\n",
        "\n",
        "data_flow_settings = {\n",
        "    'color_mode' : 'rgb',\n",
        "    'batch_size' : batch_size,\n",
        "    'shuffle' : True,\n",
        "    'seed' : 42, # Mandatory to allign shuffles between cartoon_real and cartoon_smooth\n",
        "    'class_mode' : None,\n",
        "    'interpolation' : 'bilinear',\n",
        "    'target_size' : (input_shape[0], input_shape[1])\n",
        "}\n",
        "\n",
        "def cartoon_real_generator(subset='training'):\n",
        "  cartoon_real_gen = ImageDataGenerator(\n",
        "    **data_generator_settings\n",
        "  )\n",
        "  return cartoon_real_gen.flow_from_directory(\n",
        "        **data_flow_settings,\n",
        "        # Ghibli cartoon\n",
        "        directory = path.join(folders[ghibli_index], real_folder),\n",
        "        subset = subset\n",
        "      )\n",
        "\n",
        "def cartoon_real_validation_generator():\n",
        "  return cartoon_real_generator('validation')\n",
        "\n",
        "def cartoon_smooth_generator(subset='training'):\n",
        "  cartoon_smooth_gen = ImageDataGenerator(\n",
        "    **data_generator_settings\n",
        "  )\n",
        "  return cartoon_smooth_gen.flow_from_directory(\n",
        "        **data_flow_settings,\n",
        "        # Ghibli cartoon\n",
        "        directory = path.join(folders[ghibli_index], smooth_folder),\n",
        "        subset = subset\n",
        "      )\n",
        "  \n",
        "def cartoon_smooth_validation_generator():\n",
        "  return cartoon_smooth_generator('validation')\n",
        "\n",
        "def real_generator(subset='training'):\n",
        "  real_gen = ImageDataGenerator(\n",
        "      **data_generator_settings\n",
        "  )\n",
        "  return real_gen.flow_from_directory(\n",
        "      **data_flow_settings,\n",
        "      # Flickr30k images\n",
        "      directory=flickr30k_folder,\n",
        "      subset=subset\n",
        "  )\n",
        "\n",
        "def real_validation_generator():\n",
        "  return real_generator('validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2NBdlQgjxso"
      },
      "source": [
        "gen = cartoon_real_generator()\n",
        "batches_per_epoch = len(gen)\n",
        "print(\"Batches per epoch:\", batches_per_epoch)\n",
        "del gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqumAei81Roa",
        "scrolled": true
      },
      "source": [
        "test_cartoon_real_flow = cartoon_real_generator()\n",
        "print(\"Expected steps per epoch:\", len(test_cartoon_real_flow))\n",
        "plot_grid(generated_to_images(next(test_cartoon_real_flow)), 4)\n",
        "del test_cartoon_real_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQrSxTqRX2oM"
      },
      "source": [
        "test_cartoon_edge_fake_flow = cartoon_smooth_generator()\n",
        "print(\"Expected steps per epoch:\", len(test_cartoon_edge_fake_flow))\n",
        "plot_grid(generated_to_images(next(test_cartoon_edge_fake_flow)), 4)\n",
        "del test_cartoon_edge_fake_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2w7SPwVHiPl"
      },
      "source": [
        "test_real_flow = real_generator()\n",
        "print(\"Expected steps per epoch:\", len(test_real_flow))\n",
        "plot_grid(generated_to_images(next(test_real_flow)), 4)\n",
        "del test_real_flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZfIsl-rzgH"
      },
      "source": [
        "# Cartoon-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdnnqJrr49p"
      },
      "source": [
        "## Custom Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZVztXmxfqh"
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "  def __init__(self, padding=(1, 1), **kwargs):\n",
        "    self.padding = tuple(padding)\n",
        "    # self.input_spec = [InputSpec(ndim=4)]\n",
        "    super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "  def compute_output_shape(self, s):\n",
        "    if s[1] == None:\n",
        "      return (None, None, None, s[3])\n",
        "    return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    w_pad, h_pad = self.padding\n",
        "    return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(ReflectionPadding2D, self).get_config()\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_eKtrzX8eS"
      },
      "source": [
        "class Conv2DReflection3x3(Layer):\n",
        "  def __init__(self, features, stride=1):\n",
        "    super().__init__()\n",
        "    self.reflectionPadding2D = ReflectionPadding2D()\n",
        "    self.conv2d = Conv2D(features, (3,3), strides=(stride, stride), padding='valid', use_bias=False)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.reflectionPadding2D(inputs, training=training)\n",
        "    return self.conv2d(x, training=training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QosKh8nXwVDy"
      },
      "source": [
        "## Discriminator\n",
        "Based on the Cartoon-GAN discriminator, available at [this link](https://github.com/FilipAndersson245/cartoon-gan/blob/master/models/discriminator.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWKAZhc0TtT8"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # k3n32s1\n",
        "  d = Conv2DReflection3x3(32, stride=1)(in_image)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n64s2\n",
        "  d = Conv2DReflection3x3(64, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n128s1\n",
        "  d = Conv2DReflection3x3(128, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n128s2\n",
        "  d = Conv2DReflection3x3(128, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # feature construction block\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # patch output\n",
        "  d = Conv2DReflection3x3(1, stride=1)(d)\n",
        "  #patch_out = tf.keras.activations.sigmoid(d)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, d, name='Discriminator')\n",
        "  return model\n",
        "\n",
        "D = define_discriminator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aL1dg_7WxKG"
      },
      "source": [
        "#plot_model(D, show_shapes=True, expand_nested=True)\n",
        "D.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4dAX0fbk3yk"
      },
      "source": [
        "noise = tf.random.normal([1, *input_shape])\n",
        "label_image = D(noise, training=False)\n",
        "\n",
        "plt.imshow(label_image[0, :, :, 0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmXCQikgsCVj"
      },
      "source": [
        "## Generator\n",
        "Based on the Cartoon-GAN generator, available at [this link](https://github.com/FilipAndersson245/cartoon-gan/blob/master/models/generator.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQsEIexgEot"
      },
      "source": [
        "# define the generator model\n",
        "def define_generator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # flat block\n",
        "  # k7n64s1\n",
        "  g = Conv2D(64, (7,7), strides=1, padding='same', use_bias=False)(in_image)\n",
        "  g = BatchNormalization(epsilon=epsilon, momentum=momentum)(g)\n",
        "  g = LeakyReLU(alpha=alpha)(g)\n",
        "\n",
        "  def down_block(x, n_features):\n",
        "    # k3n?s2\n",
        "    x = Conv2DReflection3x3(n_features, stride=2)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st down block\n",
        "  g = down_block(g, 128)\n",
        "\n",
        "  # 2nd down block\n",
        "  g = down_block(g, 256)\n",
        "\n",
        "  def resiual_block(x):\n",
        "    skip = x\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = Add()([x, skip])\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  for _ in range(8):\n",
        "    g = resiual_block(g)\n",
        "\n",
        "  def up_block(x, n_features):\n",
        "    # k3n?s1/2\n",
        "    x = Conv2DTranspose(n_features, (3,3), strides=2)(x)\n",
        "    x = AveragePooling2D(pool_size=(2,2), strides=1)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st up block\n",
        "  g = up_block(g, 128)\n",
        "\n",
        "  # 2nd up-block\n",
        "  g = up_block(g, 64)\n",
        "\n",
        "  # k7n3s1\n",
        "  output = Conv2D(3, (7,7), strides=1, padding='same')(g)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, output, name='Generator')\n",
        "  return model\n",
        "\n",
        "\n",
        "G = define_generator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJA_a7l72Jc"
      },
      "source": [
        "#plot_model(G, show_shapes=True, expand_nested=True)\n",
        "G.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeZ-8nTpZLqp"
      },
      "source": [
        "noise = tf.random.normal([1, *input_shape])\n",
        "generated_image = G(noise, training=False)\n",
        "plot_grid(generated_to_images(generated_image), 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKihPPW_WkZ"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaHvmumJ6fLL"
      },
      "source": [
        "### Binary Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1I8Kc6wYRka"
      },
      "source": [
        "def BCEWithLogitsLoss():\n",
        "  bce = tf.keras.losses.BinaryCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
        "  return lambda x, y: bce(y, x)\n",
        "\n",
        "def BCELoss():\n",
        "  bce = tf.keras.losses.BinaryCrossentropy(\n",
        "    from_logits=False,\n",
        "    reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
        "  return lambda x, y: bce(y, x)\n",
        "\n",
        "def test():\n",
        "  a = tf.ones((10, 64))\n",
        "  b = tf.fill((10, 64), 1.5)\n",
        "  loss = BCEWithLogitsLoss()\n",
        "  assert abs(loss(b, a).numpy() - 0.2014133) <= 1e-8\n",
        "\n",
        "  loss = BCELoss()\n",
        "  assert abs(loss(a, a).numpy() - 0.0) <= 1e-8\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL--DGLL6kJa"
      },
      "source": [
        "### Adversarial Loss\n",
        "Also called Discriminator loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2v-V58ORS95"
      },
      "source": [
        "class AdversarialLoss:\n",
        "  def __init__(self, cartoon_labels, fake_cartoon_labels):\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "    self.cartoon_labels = cartoon_labels\n",
        "    self.fake_cartoon_labels = fake_cartoon_labels\n",
        "\n",
        "  def __call__(self, cartoons_outputs, generated_fakes_outputs, cartoon_edge_fakes_outputs):\n",
        "    D_cartoon_loss = self.base_loss(cartoons_outputs, self.cartoon_labels)\n",
        "    D_generated_fake_loss = self.base_loss(generated_fakes_outputs, self.fake_cartoon_labels)\n",
        "    D_edge_fake_loss = self.base_loss(cartoon_edge_fakes_outputs, self.fake_cartoon_labels)\n",
        "\n",
        "    return D_cartoon_loss + D_generated_fake_loss + D_edge_fake_loss\n",
        "\n",
        "# alias for clarity\n",
        "DiscriminatorLoss = AdversarialLoss\n",
        "\n",
        "\n",
        "def test():\n",
        "  loss = AdversarialLoss(np.ones((10, 56, 56)), np.zeros((10, 56, 56)))\n",
        "  cartoon = tf.fill((10, 56, 56), 0.6)\n",
        "  gf = tf.fill((10, 56, 56), 0.4)\n",
        "  cartoon_edge = tf.fill((10, 56, 56), 0.3)\n",
        "  l1 = loss(cartoon, gf, cartoon_edge)\n",
        "\n",
        "  cartoon = tf.fill((10, 56, 56), 0.9)\n",
        "  gf = tf.fill((10, 56, 56), 0.3)\n",
        "  cartoon_edge = tf.fill((10, 56, 56), 0.2)\n",
        "  l2 = loss(cartoon, gf, cartoon_edge)\n",
        "\n",
        "  cartoon = tf.fill((10, 56, 56), 0.99)\n",
        "  gf = tf.fill((10, 56, 56), 0.01)\n",
        "  cartoon_edge = tf.fill((10, 56, 56), 0.01)\n",
        "  l3 = loss(cartoon, gf, cartoon_edge)\n",
        "  assert l1 > l2 > l3 > 0\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKqNjV4K6p2e"
      },
      "source": [
        "### Content Loss\n",
        "Used to force content fidelty in the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPZxQNSVtr6"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        "vgg16_model = vgg16.VGG16(include_top=False, \n",
        "                    weights='imagenet', \n",
        "                    input_shape=input_shape)\n",
        "\n",
        "vgg16_model.trainable = False\n",
        "for l in vgg16_model.layers:\n",
        "  l.trainable = False\n",
        "vgg16_cut = Sequential(vgg16_model.layers[:15], name=\"ContentLoss_VGG16\")\n",
        "vgg16_cut.trainable = False\n",
        "vgg16_cut.summary()\n",
        "\n",
        "class ContentLoss:\n",
        "  def __init__(self):\n",
        "    self.perception = lambda img: vgg16_cut(vgg16.preprocess_input(unnormalize(img) * 255.0), training=False)\n",
        "  \n",
        "  def __call__(self, outputs, targets):\n",
        "    diff = self.perception(outputs) - self.perception(targets)\n",
        "    k = tf.math.reduce_mean(tf.math.abs(diff))\n",
        "    return k\n",
        "\n",
        "def test():\n",
        "  loss = ContentLoss()\n",
        "  outputs = normalize(tf.fill((10, 224, 224, 3), 0.0))\n",
        "  assert loss(outputs, outputs) == 0.0\n",
        "  inputs = normalize(tf.fill((10, 224, 224, 3), 1.0))\n",
        "  assert loss(outputs, inputs) > 0.0\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFJmBsDb67AI"
      },
      "source": [
        "### Generator Loss\n",
        "Enforces both discriminator fooling and content fidelty from the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGF728qWboj"
      },
      "source": [
        "class GeneratorLoss:\n",
        "  def __init__(self, cartoon_labels, omega=10):\n",
        "    self.omega = tf.constant(omega, dtype=tf.float32)\n",
        "    self.content_loss = ContentLoss()\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "    self.cartoon_labels = cartoon_labels\n",
        "  \n",
        "  def __call__(self, outputs, inputs, outputs_labels):\n",
        "    return self.base_loss(outputs_labels, self.cartoon_labels) + self.omega * self.content_loss(outputs, inputs)\n",
        "\n",
        "def test():\n",
        "  loss = GeneratorLoss(tf.ones((10, 56, 56)), omega=100)\n",
        "  outputs_labels = tf.fill((10, 56, 56), 1.0)\n",
        "  outputs = tf.fill((10, 224, 224, 3), 0.0)\n",
        "  assert loss(outputs, outputs, outputs_labels) == 0.31326172\n",
        "  \n",
        "  loss = GeneratorLoss(tf.ones((10, 56, 56)), omega=10)\n",
        "  outputs_labels = tf.fill((10, 56, 56), 0.5)\n",
        "  outputs = tf.fill((10, 224, 224, 3), 0.0)\n",
        "  assert loss(outputs, outputs, outputs_labels) > 0.0\n",
        "  \n",
        "  loss = GeneratorLoss(tf.ones((10, 56, 56)), omega=100)\n",
        "  outputs_labels = tf.fill((10, 56, 56), 1.0)\n",
        "  outputs = tf.fill((10, 224, 224, 3), 0.0)\n",
        "  inputs = tf.fill((10, 224, 224, 3), 1.0)\n",
        "  assert loss(outputs, inputs, outputs_labels) > 0.0\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXXAoGW_Kao_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqWyxfkm9q5f"
      },
      "source": [
        "learning_rate = 1.5e-4\n",
        "beta1, beta2 = (.5, .99)\n",
        "weight_decay = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "309mSNxD9W1d"
      },
      "source": [
        "discriminator_optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=learning_rate, \n",
        "    beta_1=beta1, beta_2=beta2,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "generator_optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=learning_rate, \n",
        "    beta_1=beta1, beta_2=beta2,\n",
        "    weight_decay=weight_decay\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chnai6eyRLSp"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmovpB7LZzKe"
      },
      "source": [
        "### Checkpoints & History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mpmVG5PZy8O"
      },
      "source": [
        "local_checkpoint_location = './training_checkpoints/'\n",
        "history_file_name = 'history.csv'\n",
        "history_header = ['epoch', \n",
        "                  'train_discriminator_loss_mean', \n",
        "                  'train_discriminator_loss_std',\n",
        "                  'train_generator_loss_mean', \n",
        "                  'train_generator_loss_std', \n",
        "                  'val_discriminator_loss_mean', \n",
        "                  'val_discriminator_loss_std',\n",
        "                  'val_generator_loss_mean', \n",
        "                  'val_generator_loss_std', \n",
        "                  ]\n",
        "history_file_path = path.join(local_checkpoint_location, history_file_name)\n",
        "\n",
        "def reset_history():\n",
        "  with open(history_file_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',')\n",
        "    writer.writerow(history_header)\n",
        "\n",
        "def history_append(epoch, \n",
        "                   train_discriminator_loss_mean, \n",
        "                   train_discriminator_loss_std, \n",
        "                   train_generator_loss_mean, \n",
        "                   train_generator_loss_std, \n",
        "                   val_discriminator_loss_mean,\n",
        "                   val_discriminator_loss_std,\n",
        "                   val_generator_loss_mean,\n",
        "                   val_generator_loss_std):\n",
        "  with open(history_file_path, 'a', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',')\n",
        "    writer.writerow([epoch, \n",
        "                   train_discriminator_loss_mean, \n",
        "                   train_discriminator_loss_std, \n",
        "                   train_generator_loss_mean, \n",
        "                   train_generator_loss_std, \n",
        "                   val_discriminator_loss_mean,\n",
        "                   val_discriminator_loss_std,\n",
        "                   val_generator_loss_mean,\n",
        "                   val_generator_loss_std])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_mpWK3Gp4mK"
      },
      "source": [
        "#### Google Drive checkpoint backup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MopeyfiEp-C7"
      },
      "source": [
        "use_google_drive = False #@param {type:'boolean'}\n",
        "google_drive_checkpoint_path = 'Anime-Frames/Checkpoints' #@param {type: 'string'}\n",
        "reset_checkpoints = True #@param {type: 'boolean'}\n",
        "google_drive_root = '/content/drive/'\n",
        "google_drive_checkpoint_location = path.join(google_drive_root, 'MyDrive', google_drive_checkpoint_path)\n",
        "\n",
        "if use_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount(google_drive_root)\n",
        "  os.makedirs(google_drive_checkpoint_location, exist_ok=True)\n",
        "  shutil.rmtree(local_checkpoint_location, ignore_errors=True)\n",
        "  shutil.copytree(google_drive_checkpoint_location, local_checkpoint_location)\n",
        "  print(f'Local files at {local_checkpoint_location} will be backed inside {google_drive_checkpoint_location}')\n",
        "else:\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "    !rm -rf /content/drive\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "if reset_checkpoints:\n",
        "  shutil.rmtree(local_checkpoint_location, ignore_errors=True)\n",
        "if not path.isfile(history_file_path):\n",
        "  os.makedirs(local_checkpoint_location)\n",
        "  reset_history()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGZeeqabwaTD"
      },
      "source": [
        "#### Checkpoint manager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4bip6SkwdGp"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=G,\n",
        "                                 discriminator=D,\n",
        "                                 epoch=tf.Variable(0))\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, local_checkpoint_location, max_to_keep=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx-ymhLjeROc"
      },
      "source": [
        "### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8Bn4o5b5ILJM"
      },
      "source": [
        "class CartoonGAN:\n",
        "  def __init__(self,\n",
        "               checkpoint,\n",
        "               checkpoint_manager,\n",
        "               cartoon_real_generator,\n",
        "               cartoon_smooth_generator,\n",
        "               real_image_generator,\n",
        "               cartoon_real_generator_val,\n",
        "               cartoon_smooth_generator_val,\n",
        "               real_image_generator_val):\n",
        "    self.name = 'Cartoon-GAN'\n",
        "    self.checkpoint = checkpoint\n",
        "    self.checkpoint_manager = checkpoint_manager\n",
        "\n",
        "    # Checkpoint restore\n",
        "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
        "    if checkpoint_manager.latest_checkpoint:\n",
        "      print(f'Restored from {checkpoint_manager.latest_checkpoint}.')\n",
        "    else:\n",
        "      print('Initializing from scratch.')\n",
        "    self.discriminator = checkpoint.discriminator\n",
        "    self.generator = checkpoint.generator\n",
        "    self.d_optimizer = checkpoint.discriminator_optimizer\n",
        "    self.g_optimizer = checkpoint.generator_optimizer\n",
        "\n",
        "    self.cartoon_real_generator = cartoon_real_generator # cartoon real gen train\n",
        "    self.cartoon_smooth_generator = cartoon_smooth_generator # cartoon smooth gen train\n",
        "    self.cartoon_real_generator_val = cartoon_real_generator_val # cartoon real gen val\n",
        "    self.cartoon_smooth_generator_val = cartoon_smooth_generator_val # cartoon smooth gen val\n",
        "    self.real_image_generator = real_image_generator # real image gen train\n",
        "    self.real_image_generator_val = real_image_generator_val # real image gen val \n",
        "    \n",
        "    self.batches_per_epoch = len(self.cartoon_real_generator) - 1 # Last batch has unknown size\n",
        "    self.val_batches_per_epoch = len(self.cartoon_real_generator_val) - 1 # Last batch has unknown size\n",
        "\n",
        "    self.cartoon_labels = tf.ones((*D.compute_output_shape((batch_size, *input_shape)),))\n",
        "    self.fake_cartoon_labels = tf.zeros((*D.compute_output_shape((batch_size, *input_shape)),))\n",
        "\n",
        "    self.d_loss_fn = DiscriminatorLoss(self.cartoon_labels, self.fake_cartoon_labels)\n",
        "    self.g_loss_fn = GeneratorLoss(self.cartoon_labels)\n",
        "    self.bar_format = '{bar}{desc}: {percentage:3.0f}% {r_bar}'\n",
        "  \n",
        "  @tf.function\n",
        "  def _step(self,\n",
        "              x_cartoon_batch_train,\n",
        "              x_cartoon_smooth_batch_train,\n",
        "              x_real_train):\n",
        "    generated_real_train = self.generator(x_real_train, training=False)\n",
        "\n",
        "    with tf.GradientTape() as disc_tape:  \n",
        "      # Discriminator loss\n",
        "      predictions_cartoon_train = self.discriminator(x_cartoon_batch_train, training=True)\n",
        "      predictions_cartoon_smooth_train = self.discriminator(x_cartoon_smooth_batch_train, training=True)\n",
        "      predictions_generated_train = self.discriminator(generated_real_train, training=True)\n",
        "      d_loss = self.d_loss_fn(predictions_cartoon_train, predictions_generated_train, predictions_cartoon_smooth_train)\n",
        "    \n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "    self.d_optimizer.apply_gradients(\n",
        "        zip(gradients_of_discriminator, self.discriminator.trainable_variables)\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      generated_real_train = self.generator(x_real_train, training=True)\n",
        "      # Generator loss\n",
        "      generated_real_labels = self.discriminator(generated_real_train, training=False)\n",
        "      g_loss = self.g_loss_fn(generated_real_train, x_real_train, generated_real_labels)\n",
        "    \n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "    self.g_optimizer.apply_gradients(\n",
        "        zip(gradients_of_generator, self.generator.trainable_variables)\n",
        "    )\n",
        "\n",
        "    return d_loss, g_loss\n",
        "\n",
        "  @tf.function\n",
        "  def _val_step(self,\n",
        "              x_cartoon_batch_val,\n",
        "              x_cartoon_smooth_batch_val,\n",
        "              x_real_val):\n",
        "\n",
        "    generated_real_val = self.generator(x_real_val, training=False)\n",
        "    \n",
        "    # Discriminator loss\n",
        "    predictions_cartoon_val = self.discriminator(x_cartoon_batch_val, training=False)\n",
        "    predictions_cartoon_smooth_val = self.discriminator(x_cartoon_smooth_batch_val, training=False)\n",
        "    predictions_generated_val = self.discriminator(generated_real_val, training=False)\n",
        "    d_loss = self.d_loss_fn(predictions_cartoon_val, predictions_generated_val, predictions_cartoon_smooth_val)\n",
        "\n",
        "    # Generator loss (could have been computed from discriminator after one step of training)\n",
        "    generated_real_labels = self.discriminator(generated_real_val, training=False)\n",
        "    g_loss = self.g_loss_fn(generated_real_val, x_real_val, generated_real_labels)\n",
        "\n",
        "    return d_loss, g_loss\n",
        "\n",
        "  def train(self, epochs):\n",
        "    starting_epoch = int(self.checkpoint.epoch)\n",
        "    for epoch in tqdm(range(starting_epoch, epochs),\n",
        "                      total=epochs,\n",
        "                      initial=starting_epoch,\n",
        "                      position=0,\n",
        "                      desc=f'Training model {self.name}',\n",
        "                      bar_format=self.bar_format):\n",
        "\n",
        "      # train phase\n",
        "      epoch_progress = tqdm(range(self.batches_per_epoch), \n",
        "                            total=self.batches_per_epoch, \n",
        "                            position=1,\n",
        "                            desc=f'Training epoch {epoch}',\n",
        "                            bar_format=self.bar_format)\n",
        "      train_d_loss_sum = 0\n",
        "      train_d_loss_sum_squared = 0\n",
        "      train_g_loss_sum = 0\n",
        "      train_g_loss_sum_squared = 0\n",
        "      train_step_count = 0\n",
        "      \n",
        "      for (step,\n",
        "          x_cartoon_batch_train, \n",
        "          x_cartoon_smooth_batch_train, \n",
        "          x_real_train) in zip(\n",
        "             epoch_progress,\n",
        "             self.cartoon_real_generator, \n",
        "             self.cartoon_smooth_generator,\n",
        "             self.real_image_generator):\n",
        "        \n",
        "        d_loss, g_loss = self._step(x_cartoon_batch_train,\n",
        "                                    x_cartoon_smooth_batch_train,\n",
        "                                    x_real_train)\n",
        "        d_loss = d_loss.numpy()\n",
        "        g_loss = g_loss.numpy()\n",
        "        \n",
        "        epoch_progress.set_postfix({\n",
        "          'Discriminator Loss' : f'{d_loss:.4f}',\n",
        "          'Generator Loss' : f'{g_loss:.4f}'\n",
        "        })\n",
        "        \n",
        "        train_d_loss_sum += d_loss\n",
        "        train_d_loss_sum_squared += d_loss * d_loss\n",
        "        train_g_loss_sum += g_loss\n",
        "        train_g_loss_sum_squared += g_loss * g_loss\n",
        "        train_step_count += 1\n",
        "        \n",
        "      self.cartoon_real_generator.reset()\n",
        "      self.cartoon_smooth_generator.reset()\n",
        "      self.real_image_generator.reset()\n",
        "      \n",
        "      # Compute mean loss and variance for historical data\n",
        "      train_d_loss_mean = train_d_loss_sum / train_step_count\n",
        "      train_d_loss_std = np.sqrt(train_d_loss_sum_squared / train_step_count - train_d_loss_mean * train_d_loss_mean)\n",
        "      train_g_loss_mean = train_g_loss_sum / train_step_count\n",
        "      train_g_loss_std = np.sqrt(train_g_loss_sum_squared / train_step_count - train_g_loss_mean * train_g_loss_mean)\n",
        "\n",
        "      # validation phase\n",
        "      epoch_val_progress = tqdm(total=self.val_batches_per_epoch,\n",
        "                                position=1,\n",
        "                                desc=f'Validation epoch {epoch}',\n",
        "                                bar_format=self.bar_format)\n",
        "      val_d_loss_sum = 0\n",
        "      val_d_loss_sum_squared = 0\n",
        "      val_g_loss_sum = 0\n",
        "      val_g_loss_sum_squared = 0\n",
        "      val_step_count = 0\n",
        "      \n",
        "      for crgv, csgv, rigv, _ in zip(self.cartoon_real_generator_val, \n",
        "                                     self.cartoon_smooth_generator_val, \n",
        "                                     self.real_image_generator_val, \n",
        "                                     range(self.val_batches_per_epoch)):\n",
        "        \n",
        "        d_val_loss, g_val_loss = self._val_step(crgv, csgv, rigv)\n",
        "        d_val_loss = d_val_loss.numpy()\n",
        "        g_val_loss = g_val_loss.numpy()\n",
        "        \n",
        "        val_d_loss_sum += d_val_loss\n",
        "        val_d_loss_sum_squared += d_val_loss * d_val_loss\n",
        "        val_g_loss_sum += g_val_loss\n",
        "        val_g_loss_sum_squared += g_val_loss * g_val_loss\n",
        "        val_step_count += 1\n",
        "        \n",
        "        epoch_val_progress.update(1)\n",
        "      \n",
        "      # Compute mean loss and variance for historical data\n",
        "      val_d_loss_mean = val_d_loss_sum / val_step_count\n",
        "      val_d_loss_std = np.sqrt(val_d_loss_sum_squared / val_step_count - val_d_loss_mean * val_d_loss_mean)\n",
        "      val_g_loss_mean = val_g_loss_sum / val_step_count\n",
        "      val_g_loss_std = np.sqrt(val_g_loss_sum_squared / val_step_count - val_g_loss_mean * val_g_loss_mean)\n",
        "      \n",
        "      epoch_val_progress.set_postfix({\n",
        "        'Discriminator Loss' : f'{val_d_loss_mean:.4f}',\n",
        "        'Generator Loss' : f'{val_g_loss_mean:.4f}'\n",
        "      })\n",
        "      epoch_val_progress.close()\n",
        "      \n",
        "      self.cartoon_real_generator_val.reset()\n",
        "      self.cartoon_smooth_generator_val.reset()\n",
        "      self.real_image_generator_val.reset()\n",
        "      \n",
        "      # checkpoint phase\n",
        "      epoch_checkpoint_progress = tqdm(total=3 if use_google_drive else 2,\n",
        "                                 position=1,\n",
        "                                 desc=f'Saving model checkpoints and history for epoch {epoch}',\n",
        "                                 bar_format=self.bar_format)\n",
        "      self.checkpoint.epoch.assign_add(1)\n",
        "      save_path = self.checkpoint_manager.save()\n",
        "      epoch_checkpoint_progress.update(1)\n",
        "      epoch_checkpoint_progress.set_description(f'Saved checkpoint for epoch {epoch}: {save_path}')\n",
        "      \n",
        "      if use_google_drive:\n",
        "        shutil.rmtree(google_drive_checkpoint_location)\n",
        "        shutil.copytree(self.checkpoint_manager.directory, google_drive_checkpoint_location)\n",
        "        epoch_checkpoint_progress.update(1)\n",
        "        epoch_checkpoint_progress.set_description(f'Saved checkpoint backup for epoch {epoch}: {save_path} -> {google_drive_checkpoint_location}')\n",
        "      \n",
        "      # history save\n",
        "      history_append(epoch, train_d_loss_mean, train_d_loss_std, train_g_loss_mean, train_g_loss_std, val_d_loss_mean, val_d_loss_std, val_g_loss_mean, val_g_loss_std)\n",
        "      epoch_checkpoint_progress.update(1)\n",
        "      epoch_checkpoint_progress.set_description(f'Saved history for epoch {epoch}: {save_path}')\n",
        "      \n",
        "      epoch_checkpoint_progress.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GQa7MRDmgs1"
      },
      "source": [
        "model = CartoonGAN(checkpoint,\n",
        "                   checkpoint_manager,\n",
        "                   cartoon_real_generator(), \n",
        "                   cartoon_smooth_generator(), \n",
        "                   real_generator(),\n",
        "                   cartoon_real_validation_generator(),\n",
        "                   cartoon_smooth_validation_generator(),\n",
        "                   real_validation_generator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwmOwg7TeYuq"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSlPFOQTaj5",
        "scrolled": true
      },
      "source": [
        "# d_losses, g_losses = \n",
        "model.train(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4YsZWLrW5sT"
      },
      "source": [
        "cartoon_images = next(cartoon_real_generator())\n",
        "cartoon_smoothed_images = next(cartoon_smooth_generator())\n",
        "black_images = np.full((2, 224, 224, 3), 0.0)\n",
        "\n",
        "print('cartoon')\n",
        "plot_grid(D(cartoon_images).numpy().squeeze(), 4)\n",
        "print('smoothed')\n",
        "plot_grid(D(cartoon_smoothed_images).numpy().squeeze(), 4)\n",
        "print('black')\n",
        "plot_grid(D(black_images).numpy().squeeze(), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5orBaqsRsCA"
      },
      "source": [
        "real_images = next(real_generator())\n",
        "black_images = np.full((4, 224, 224, 3), 0.0)\n",
        "\n",
        "print('real images')\n",
        "plot_grid(generated_to_images(real_images), 4)\n",
        "print('cartoon generated')\n",
        "plot_grid(generated_to_images(G(real_images)), 4)\n",
        "print('black')\n",
        "plot_grid(generated_to_images(G(black_images)), 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaT2CU9rrb0T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}