{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moviefy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideEva/Moviefy/blob/main/Moviefy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cIJV64OLD8N"
      },
      "source": [
        "# Problem analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9K_1ajnk6i"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO4pM6X-woCT"
      },
      "source": [
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XCqb1vMvbSF"
      },
      "source": [
        "films_data = {\n",
        "    \"Ghibli\": \"1RR18MAxLoZQWsxrmfb1hYif2MhOcsgO2\"\n",
        "}\n",
        "keys = list(films_data.keys())\n",
        "films_data[keys[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFFC2I7nmIK"
      },
      "source": [
        "def load_data(name, id_txt):\n",
        "\n",
        "  file_name = f'list-{name}.txt'\n",
        "\n",
        "  ! gdown --id \"$id_txt\" -O \"$file_name\"\n",
        "\n",
        "  lines = []\n",
        "  with open(file_name, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  ! mkdir \"$name\"\n",
        "\n",
        "  for line in lines:\n",
        "    id = line.strip()\n",
        "    ! cd \"$name\" && gdown --id \"$id\"\n",
        "\n",
        "  zip_files = glob(f'{name}/*.zip')\n",
        "  for zip_file in zip_files:\n",
        "    ! unzip -qo \"$zip_file\" -d \"$name\"\n",
        "    ! rm \"$zip_file\"\n",
        "  \n",
        "  return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA9UnZ6nqhwK"
      },
      "source": [
        "folders = [load_data(studio_name, id_list_id) for studio_name, id_list_id in films_data.items()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtTLjUKToxO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYnk7xOGrwh"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, InputSpec, LeakyReLU, Input, Conv2D, Activation, Concatenate, Conv2DTranspose, BatchNormalization, AveragePooling2D, Add\n",
        "from tensorflow import pad\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4OJRPRrvTD"
      },
      "source": [
        "# Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ort4c0Hvkv"
      },
      "source": [
        "input_shape = (224,224,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZfIsl-rzgH"
      },
      "source": [
        "# Cartoon-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdnnqJrr49p"
      },
      "source": [
        "## Utility Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZVztXmxfqh"
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "  def __init__(self, padding=(1, 1), **kwargs):\n",
        "    self.padding = tuple(padding)\n",
        "    # self.input_spec = [InputSpec(ndim=4)]\n",
        "    super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "  def compute_output_shape(self, s):\n",
        "    if s[1] == None:\n",
        "      return (None, None, None, s[3])\n",
        "    return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    w_pad, h_pad = self.padding\n",
        "    return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(ReflectionPadding2D, self).get_config()\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_eKtrzX8eS"
      },
      "source": [
        "class Conv2DReflection3x3(Layer):\n",
        "  def __init__(self, features, stride=1):\n",
        "    super().__init__()\n",
        "    self.reflectionPadding2D = ReflectionPadding2D()\n",
        "    self.conv2d = Conv2D(features, (3,3), strides=(stride, stride), padding='valid', use_bias=False)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.reflectionPadding2D(inputs, training=training)\n",
        "    return self.conv2d(x, training=training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QosKh8nXwVDy"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWKAZhc0TtT8"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # k3n32s1\n",
        "  d = Conv2DReflection3x3(32, stride=1)(in_image)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n64s2\n",
        "  d = Conv2DReflection3x3(64, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n128s1\n",
        "  d = Conv2DReflection3x3(128, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # k3n128s2\n",
        "  d = Conv2DReflection3x3(128, stride=2)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # feature construction block\n",
        "  # k3n256s1\n",
        "  d = Conv2DReflection3x3(256, stride=1)(d)\n",
        "  d = BatchNormalization(epsilon=epsilon, momentum=momentum)(d)\n",
        "  d = LeakyReLU(alpha=alpha)(d)\n",
        "\n",
        "  # patch output\n",
        "  patch_out = Conv2DReflection3x3(1, stride=1)(d)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, patch_out)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTqNuZ0TuIb"
      },
      "source": [
        "D = define_discriminator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aL1dg_7WxKG"
      },
      "source": [
        "plot_model(D, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmXCQikgsCVj"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQsEIexgEot"
      },
      "source": [
        "# define the generator model\n",
        "def define_generator(image_shape):\n",
        "  alpha = 0.2\n",
        "  epsilon = 1e-5\n",
        "  momentum = 0.1\n",
        "\n",
        "  # source image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  # flat block\n",
        "  # k7n64s1\n",
        "  g = Conv2D(64, (7,7), strides=1, padding='same', use_bias=False)(in_image)\n",
        "  g = BatchNormalization(epsilon=epsilon, momentum=momentum)(g)\n",
        "  g = LeakyReLU(alpha=alpha)(g)\n",
        "\n",
        "  def down_block(x, n_features):\n",
        "    # k3n?s2\n",
        "    x = Conv2DReflection3x3(n_features, stride=2)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st down block\n",
        "  g = down_block(g, 128)\n",
        "\n",
        "  # 2nd down block\n",
        "  g = down_block(g, 256)\n",
        "\n",
        "  def resiual_block(x):\n",
        "    skip = x\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    # k3n256s1\n",
        "    x = Conv2DReflection3x3(256, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = Add()([x, skip])\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  for _ in range(8):\n",
        "    g = resiual_block(g)\n",
        "\n",
        "  def up_block(x, n_features):\n",
        "    # k3n?s1/2\n",
        "    x = Conv2DTranspose(n_features, (3,3), strides=2)(x)\n",
        "    x = AveragePooling2D(pool_size=(2,2), strides=1)(x)\n",
        "    # k3n?s1\n",
        "    x = Conv2DReflection3x3(n_features, stride=1)(x)\n",
        "    x = BatchNormalization(epsilon=epsilon, momentum=momentum)(x)\n",
        "    x = LeakyReLU(alpha=alpha)(x)\n",
        "    return x\n",
        "\n",
        "  # 1st up block\n",
        "  g = up_block(g, 128)\n",
        "\n",
        "  # 2nd up-block\n",
        "  g = up_block(g, 64)\n",
        "\n",
        "  # k7n3s1\n",
        "  output = Conv2D(3, (7,7), strides=1, padding='same')(g)\n",
        "\n",
        "  # define model\n",
        "  model = Model(in_image, output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbrwJll72Jc"
      },
      "source": [
        "G = define_generator(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJA_a7l72Jc"
      },
      "source": [
        "plot_model(G, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKihPPW_WkZ"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1I8Kc6wYRka"
      },
      "source": [
        "def BCEWithLogitsLoss():\n",
        "  return tf.keras.losses.BinaryCrossEntropy(\n",
        "    from_logits=True,\n",
        "    reduction=tf.keras.losses.Reduction.NONE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2v-V58ORS95"
      },
      "source": [
        "class AdversarialLoss:\n",
        "  def __init__(self, cartoon_labels, fake_cartoon_labels):\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "    self.cartoon_labels = cartoon_labels\n",
        "    self.fake_cartoon_labels = fake_cartoon_labels\n",
        "\n",
        "  def __call__(self, cartoon, generated_fake, cartoon_edge_fake):\n",
        "    D_cartoon_loss = self.base_loss(cartoon, self.cartoon_labels)\n",
        "    D_generated_fake_loss = self.base_loss(generated_fake, self.fake_cartoon_labels)\n",
        "    D_edge_fake_loss = self.base_loss(cartoon_edge_fake, self.fake_cartoon_labels)\n",
        "\n",
        "    return D_cartoon_loss + D_generated_fake_loss + D_edge_fake_loss\n",
        "\n",
        "# alias for clarity\n",
        "DiscriminatorLoss = AdversarialLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPZxQNSVtr6"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "class ContentLoss:\n",
        "  def __init__(self):\n",
        "    self.perception = vgg19.predict\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    diff = self.perception(outputs) - self.perception(inputs)\n",
        "    k = tf.norm(diff, ord=1)\n",
        "    return k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGF728qWboj"
      },
      "source": [
        "class GeneratorLoss:\n",
        "  def __init__(self, omega=10):\n",
        "    self.omega = omega\n",
        "    self.content_loss = ContentLoss()\n",
        "    self.base_loss = BCEWithLogitsLoss()\n",
        "  \n",
        "  def __call__(self, outputs, inputs):\n",
        "    return self.base_loss(outputs, inputs) + self.omega * self.content_loss(outputs, inputs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}